# LogWatch â€” Federated Deep Learning Based Log Anomaly Detection System

LogWatch is a privacy-preserving deep learning based log anomaly detection system that uses LSTM Autoencoders and Federated Learning to detect anomalies in distributed system logs without sharing raw log data.

This project implements a complete end-to-end pipeline including log parsing, sequence modeling, anomaly detection, federated training, evaluation, and visualization.

---

## ðŸ“Š Project Presentation

You can view the WatchLog project presentation here:

ðŸ”— [WatchLog PPT Presentation](https://docs.google.com/presentation/d/1jX7OODJnP09QK0rDgZv_pJZ5Cvx0rn_T/edit?usp=sharing)

---

# Overview

Modern distributed systems generate massive volumes of logs. Detecting anomalies manually or using rule-based systems is inefficient, non-scalable, and incapable of detecting unknown failures.

LogWatch solves this problem using:

- Deep Learning (LSTM Autoencoder)
- Federated Learning (Flower Framework)
- Log Parsing using template extraction
- Sliding window sequence modeling
- Unsupervised anomaly detection
- Privacy-preserving distributed training

---

# Key Features

- Fully automated log anomaly detection pipeline
- LSTM Autoencoder based sequence reconstruction model
- Federated learning support for distributed privacy-preserving training
- Log parsing using Drain-inspired template extraction
- Sliding window sequence generation
- Reconstruction error based anomaly detection
- Multiple thresholding methods:
  - Percentile
  - Standard deviation
  - Interquartile range (IQR)
- Complete evaluation system:
  - Accuracy
  - Precision
  - Recall
  - F1 Score
  - Confusion Matrix
  - ROC Curve
- Visualization of anomalies
- Experiment tracking and logging
- GPU support (CUDA)

---

# System Architecture

## Pipeline Flow

Raw Logs
â†“
Log Parser (Drain)
â†“
Structured Logs (Event IDs)
â†“
Sequence Builder (Sliding Window)
â†“
LSTM Autoencoder Training
â†“
Reconstruction Error Computation
â†“
Threshold Calculation
â†“
Anomaly Detection
â†“
Evaluation and Visualization

## Federated Learning Flow

```
Client Logs â†’ Local Training â†’ Model Weights â†’ Server Aggregation â†’ Global Model
```

Raw log data never leaves client machines, ensuring privacy.

---

# Machine Learning Model

## Model: LSTM Autoencoder

Purpose:
Learn normal log sequence patterns and detect anomalies using reconstruction error.

Concept:

- Normal sequence â†’ Low reconstruction error
- Anomalous sequence â†’ High reconstruction error

Model components:

- Encoder LSTM
- Latent vector representation
- Decoder LSTM
- Reconstruction error computation

---

# Dataset

Default dataset used:

HDFS Log Dataset

Source:
https://github.com/logpai/loghub

Contains:

- Raw system logs
- Ground truth anomaly labels

---

# Technologies Used

- Python
- PyTorch
- NumPy
- Pandas
- Matplotlib
- Scikit-learn
- Flower (Federated Learning)
- YAML
- Requests
- TQDM

---

# Project Structure

```
LogWatch/
â”‚
â”œâ”€â”€ main.py
â”œâ”€â”€ config.yaml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ model.pth
â”œâ”€â”€ results.csv
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw_logs/
â”‚   â”‚   â”œâ”€â”€ HDFS.log
â”‚   â”‚   â””â”€â”€ anomaly_label.csv
â”‚   â”‚
â”‚   â”œâ”€â”€ parsed_logs/
â”‚   â”‚   â””â”€â”€ parsed.csv
â”‚   â”‚
â”‚   â””â”€â”€ processed/
â”‚       â””â”€â”€ sequences.npy
â”‚
â”œâ”€â”€ log_parsing/
â”‚   â””â”€â”€ drain_parser.py
â”‚
â”œâ”€â”€ feature_engineering/
â”‚   â””â”€â”€ sequence_features.py
â”‚
â”œâ”€â”€ model/
â”‚   â”œâ”€â”€ lstm_autoencoder.py
â”‚   â””â”€â”€ trainer.py
â”‚
â”œâ”€â”€ thresholding/
â”‚   â””â”€â”€ threshold.py
â”‚
â”œâ”€â”€ visualization/
â”‚   â”œâ”€â”€ anomaly_plots.py
â”‚   â””â”€â”€ roc_curve.py
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ config_loader.py
â”‚   â”œâ”€â”€ data_downloader.py
â”‚   â”œâ”€â”€ logger.py
â”‚   â”œâ”€â”€ save_results.py
â”‚   â””â”€â”€ experiment_logger.py
â”‚
â”œâ”€â”€ federated/
â”‚   â”œâ”€â”€ client.py
â”‚   â”œâ”€â”€ server.py
â”‚   â””â”€â”€ data_partition.py
â”‚
â”œâ”€â”€ evaluation.py
â”‚
â””â”€â”€ experiments/
    â””â”€â”€ experiment_*.json
```

---

# Installation

Clone the repository:

```bash
git clone https://github.com/solvingharshproblems/WatchLog.git
cd WatchLog
```

Install dependencies:

pip install -r requirements.txt

Run Complete Pipeline:

python main.py

This will automatically:
	â€¢	Download dataset
	â€¢	Parse logs
	â€¢	Build sequences
	â€¢	Train LSTM model
	â€¢	Detect anomalies
	â€¢	Evaluate performance
	â€¢	Generate plots
	â€¢	Save experiment results

Output Files Generated:

model.pth
results.csv
experiments/
plots/

Evaluation Metrics:

The system evaluates performance using:
	â€¢	Accuracy
	â€¢	Precision
	â€¢	Recall
	â€¢	F1 Score
	â€¢	Confusion Matrix
	â€¢	ROC Curve

Example output:

Accuracy  : 0.96
Precision : 0.94
Recall    : 0.95
F1 Score  : 0.945

Research Contributions

This project demonstrates:
	â€¢	Deep sequence modeling for anomaly detection
	â€¢	Federated learning for privacy-preserving ML
	â€¢	Real-world distributed log anomaly detection pipeline
	â€¢	End-to-end ML system engineering
	â€¢	Production-style ML pipeline implementation

Applications
	â€¢	Cloud infrastructure monitoring
	â€¢	Cybersecurity intrusion detection
	â€¢	Distributed system monitoring
	â€¢	Data center fault detection
	â€¢	DevOps automation

Future Improvements
	â€¢	Transformer-based anomaly detection
	â€¢	Real-time streaming support
	â€¢	Online learning capability
	â€¢	Explainable anomaly detection
	â€¢	Web dashboard visualization
